{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "8040b9b4-4075-4dbb-92db-b2d31a3d1e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cylib.factor_backtest.factor_exp_engine import (get_needing_basic_factors, \n",
    "                                                    exec_and_eval_exp)\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0597e0f-842d-4b5a-8895-4d597d95195d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 所需提交一：提交因子表达式所需的算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "8c55441a-bd4f-42cb-8680-c102a2792eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX(A, B) - 在A、B中选择最大的数\n",
    "def MAX(A: pd.DataFrame, B: pd.DataFrame) -> pd.DataFrame:\n",
    "    if type(B) == int or float:\n",
    "        max_df = pd.DataFrame(np.maximum(A.values, B), index=A.index, columns=A.columns)\n",
    "    elif type(B) == pd.DataFrame:\n",
    "        max_df = pd.DataFrame(np.maximum(A.values, B.values), index=A.index, columns=A.columns)\n",
    "    return max_df\n",
    "\n",
    "# MIN(A, B) - 在A、B中选择最小的数\n",
    "def MIN(A: pd.DataFrame, B: pd.DataFrame) -> pd.DataFrame:\n",
    "    if type(B) == int or float:\n",
    "        min_df = pd.DataFrame(np.minimum(A.values, B), index=A.index, columns=A.columns)\n",
    "    elif type(B) == pd.DataFrame:\n",
    "        min_df = pd.DataFrame(np.minimum(A.values, B.values), index=A.index, columns=A.columns)\n",
    "    return min_df\n",
    "\n",
    "def ABS(price_df):\n",
    "    return abs(price_df)\n",
    "\n",
    "# SUM(A, n) - 序列A过去n天的求和\n",
    "def SUM(A: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    sum_df = A.rolling(window=n).sum()\n",
    "    return sum_df\n",
    "\n",
    "# SIGN(A) - 符号函数\n",
    "def SIGN(A: pd.DataFrame) -> pd.DataFrame:\n",
    "    sign_df = np.sign(A)\n",
    "    return pd.DataFrame(sign_df, index=A.index, columns=A.columns)\n",
    "\n",
    "# CORR(A, B, n) - 序列A、B过去n天的相关系数\n",
    "def CORR(A: pd.DataFrame, B: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    corr_df = A.rolling(window=n).corr(other=B)\n",
    "    return corr_df\n",
    "\n",
    "# COVARIANCE(A, B, n) - 序列A、B过去n天的协方差\n",
    "def COVARIANCE(A: pd.DataFrame, B: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    cov_df = A.rolling(window=n).cov(other=B)\n",
    "    return cov_df\n",
    "\n",
    "# STD1(A) - 序列A的标准差\n",
    "def STD1(A: pd.DataFrame) -> pd.DataFrame:\n",
    "    std_df = A.std()\n",
    "    return std_df\n",
    "\n",
    "# STD2(A, n) - 序列A过去n天的标准差\n",
    "def STD2(A: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    std_df = A.rolling(window=n).std()\n",
    "    return std_df\n",
    "\n",
    "# DELAY(A, n) - A_i-n\n",
    "def DELAY(A: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    delay_df = A.shift(n)\n",
    "    return delay_df\n",
    "\n",
    "def DELTA(df, n: int):\n",
    "    df_shift1 = df.shift(n)\n",
    "    return df_shift1 - df\n",
    "\n",
    "def RANK(df):\n",
    "    return df.rank(axis=0)\n",
    "\n",
    "# MEAN(A, n) - 序列A过去n天的均值\n",
    "def MEAN(A: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    mean_df = A.rolling(window=n).mean()\n",
    "    return mean_df\n",
    "\n",
    "# COUNT(condition, n) - 计算前n期满足条件condition的样本个数\n",
    "def COUNT(condition: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    count_df = condition.rolling(window=n).sum()\n",
    "    return count_df\n",
    "\n",
    "# LOG(A) - 自然对数函数\n",
    "def LOG(A: pd.DataFrame) -> pd.DataFrame:\n",
    "    A.replace(0, np.nan, inplace = True)\n",
    "    log_df = np.log(A)\n",
    "    df = pd.DataFrame(log_df, index=A.index, columns=A.columns)\n",
    "    # df.replace(-np.inf, 0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# TSMAX(A, n) - 序列A过去n天的最大值\n",
    "def TSMAX(A: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    tsmax_df = A.rolling(window=n).max()\n",
    "    return tsmax_df\n",
    "\n",
    "# TSRANK(A, n) - 序列A的末位值在过去n天的顺序排位\n",
    "def TSRANK(A: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    rank_df = A.rolling(window=n).apply(lambda x: x.rank(method = 'min').iloc[-1])\n",
    "    return rank_df\n",
    "\n",
    "# HIGHDAY(A, n) - 计算A前n期时间序列中最大值距离当前时点的间隔\n",
    "def HIGHDAY(A: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    high_day_df = A.rolling(window=n).apply(lambda x: len(x) - np.argmax(x) - 1)\n",
    "    return high_day_df\n",
    "\n",
    "# LOWDAY(A, n) - 计算A前n期时间序列中最小值距离当前时点的间隔\n",
    "def LOWDAY(A: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    low_day_df = A.rolling(window=n).apply(lambda x: len(x) - np.argmin(x) - 1)\n",
    "    return low_day_df\n",
    "\n",
    "# DECAYLINEAR(A, d) - 对A序列计算移动平均加权\n",
    "def DECAYLINEAR(A: pd.DataFrame, d: int) -> pd.DataFrame:\n",
    "    weights = np.arange(1, d + 1)/ np.sum(np.arange(1, d + 1))\n",
    "    decay_df = A.rolling(window=d).apply(lambda x: np.dot(x, weights))\n",
    "    return decay_df\n",
    "\n",
    "'''\n",
    "这是一个计算简单移动平均线（Simple Moving Average，SMA）的函数，输入\n",
    "参数包括一个 Pandas DataFrame A，以及两个整数 n 和 m，输出结果也是一个\n",
    "Pandas DataFrame。\n",
    "\n",
    "具体来说，该函数首先对输入的 DataFrame A 进行了一些处理，去除其中所有\n",
    "缺失值 NaN，并用 0 填充。然后创建了一个新的 DataFrame sma_df，用于保存\n",
    "计算得到的 SMA 值。\n",
    "\n",
    "接下来，通过遍历 A 的每一行数据，计算对应的 SMA 值。如果当前行的索引 i 小\n",
    "于 1，则直接将该行数据添加到 sma_df 中；如果 i 大于等于 1，\n",
    "则根据公式：next_sma = (A.iloc[i] * m + sma_df.iloc[i - 1] * (n - m)) / n，\n",
    "计算出当前行的 SMA 值 next_sma，并将其添加到 sma_df 中。\n",
    "\n",
    "最后，将 sma_df 的索引设置为 A 的最后 len(sma_df) 行数据的索引，并返回 sma_df。\n",
    "\n",
    "该函数的作用是计算简单移动平均线，通过调用该函数可以方便地得到 SMA 值，并进行\n",
    "进一步的分析和处理。\n",
    "'''\n",
    "\n",
    "def SMA(A: pd.DataFrame, n: int, m: int) -> pd.DataFrame:\n",
    "    A=A.copy().dropna(how='all').fillna(0)\n",
    "    sma_df = pd.DataFrame(columns = A.columns)\n",
    "    for i in range(len(A)):\n",
    "        if i < 1:\n",
    "            sma_df.loc[i,:]=A.iloc[i]\n",
    "        else:\n",
    "            next_sma = (A.iloc[i] * m + sma_df.iloc[i - 1] * (n - m)) / n\n",
    "            sma_df.loc[i,:]=next_sma\n",
    "    sma_df.index = A.index[-len(sma_df):]\n",
    "    return sma_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251e18b-d20a-4c67-8ce2-6cc5e7106a9e",
   "metadata": {},
   "source": [
    "#### 所需提交二：提交存储因子表达式的字典"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb5d5e",
   "metadata": {},
   "source": [
    "In a factor expression, the factor name is followed by parentheses containing two parts: the factor expression and the required data entries.\n",
    "\n",
    "- Factor expression: This represents how the factor is calculated or the logic behind it. It can be a mathematical operation, function call, conditional statement, etc., used to calculate and generate the factor value.\n",
    "\n",
    "- Required data entries: This indicates the number of data entries needed to compute the factor. It specifies the size of the historical data window to be considered when calculating the factor.\n",
    "\n",
    "For example, if we have a factor named \"MA5\" with a factor expression of \"mean(CLOSE, 5)\", the required data entries would be 5. This means that when calculating the \"MA5\" factor, the past 5 periods of closing price data are used as input. Therefore, the \"mean\" function is applied to these 5 data points to compute the average, which becomes the factor value.\n",
    "\n",
    "The required data entries can be defined and adjusted based on the specific factor's calculation logic and requirements. It determines the size of the historical data window considered during factor calculation, thus affecting the resulting factor values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "46b33e3f-7d8a-484d-b121-48f1379a78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor_def_dict = \\\n",
    "# {'alpha191_022': ('MEAN(((CLOSE_DF-MEAN(CLOSE_DF,6))/MEAN(CLOSE_DF,6)-DELAY((CLOSE_DF-MEAN(CLOSE_DF,6))/MEAN(CLOSE_DF,6),3)),12)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.018\n",
    "\n",
    "factor_def_dict = \\\n",
    "{'alpha_01': ('-1 * CORR(RANK(DELTA(LOG(VOLUME_DF), 1)), RANK(((CLOSE_DF - OPEN_DF) / OPEN_DF)), 6)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.024\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_02': ('-1 * DELTA((((CLOSE_DF - LOW_DF) - (HIGH_DF - CLOSE_DF)) / (HIGH_DF - LOW_DF)), 1)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.01566\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_05': ('-1 * TSMAX(CORR(TSRANK(VOLUME_DF, 5), TSRANK(HIGH_DF, 5), 5), 3)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.034\n",
    "# 运行时间长，13mins\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_06': ('RANK(SIGN(DELTA((((OPEN_DF * 0.85) + (HIGH_DF * 0.15))), 4))) * -1', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.053\n",
    "\n",
    "# factor_def_dict = {'alpha_14': ('CLOSE_DF - DELAY(CLOSE_DF, 5)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.027\n",
    "\n",
    "# factor_def_dict = {'alpha_15': ('OPEN_DF / DELAY(CLOSE_DF, 1) - 1', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.023\n",
    "\n",
    "# factor_def_dict = {'alpha_18': ('CLOSE_DF / DELAY(CLOSE_DF, 5)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.033\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_20': ('(CLOSE_DF - DELAY(CLOSE_DF, 6)) / DELAY(CLOSE_DF, 6) * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.033\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_29': ('(CLOSE_DF - DELAY(CLOSE_DF, 6)) / DELAY(CLOSE_DF, 6) * VOLUME_DF', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.031\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_31': ('(CLOSE_DF - MEAN(CLOSE_DF, 12)) / MEAN(CLOSE_DF, 12) * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.039\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_32': ('-1 * SUM(RANK(CORR(RANK(HIGH_DF), RANK(VOLUME_DF), 3)), 3)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.03\n",
    "\n",
    "# factor_def_dict = {'alpha_34': ('MEAN(CLOSE_DF, 12) / CLOSE_DF', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.039\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_42': ('(-1 * RANK(STD2(HIGH_DF, 10))) * CORR(HIGH_DF, VOLUME_DF, 10)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.061\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_46': ('(MEAN(CLOSE_DF, 3) + MEAN(CLOSE_DF, 6) + MEAN(CLOSE_DF, 12) + MEAN(CLOSE_DF, 24)) / (4 * CLOSE_DF)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.043\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_53': ('COUNT(CLOSE_DF > DELAY(CLOSE_DF, 1), 12) / 12 * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.027\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_54': ('-1 * RANK((STD1(ABS(CLOSE_DF - OPEN_DF)) + (CLOSE_DF - OPEN_DF)) + CORR(CLOSE_DF, OPEN_DF, 10))', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.016\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_58': ('COUNT(CLOSE_DF > DELAY(CLOSE_DF, 1), 20) / 20 * 100', 22)}\n",
    "# total loss = 0.058\n",
    "# IC mean = 0.0239\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_62': ('(-1 * CORR(HIGH_DF, RANK(VOLUME_DF), 5))', 22)}\n",
    "# total loss = 0.012\n",
    "# IC mean = 0.038\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_65': ('MEAN(CLOSE_DF, 6) / CLOSE_DF', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.032\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_70': ('STD2(AMOUNT_DF, 6)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.088\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_71': ('(CLOSE_DF - MEAN(CLOSE_DF, 24)) / MEAN(CLOSE_DF, 24) * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.047\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_76': ('STD2(ABS((CLOSE_DF / DELAY(CLOSE_DF, 1) - 1)) / VOLUME_DF, 20) / MEAN(ABS((CLOSE_DF / DELAY(CLOSE_DF, 1)-  1)) / VOLUME_DF, 20) ', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.005\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_80': ('(VOLUME_DF - DELAY(VOLUME_DF, 5)) / DELAY(VOLUME_DF, 5) * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.026\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_83': ('-1 * RANK(COVIANCE(RANK(HIGH_DF), RANK(VOLUME_DF), 5))', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "# 运行不出\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_88': ('(CLOSE_DF - DELAY(CLOSE_DF, 20)) / DELAY(CLOSE_DF, 20) * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.044\n",
    "\n",
    "# factor_def_dict = {'alpha_95': ('STD2(AMOUNT_DF, 20)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.081\n",
    "\n",
    "# factor_def_dict = {'alpha_97': ('STD2(VOLUME_DF, 10)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.046\n",
    "\n",
    "# factor_def_dict = {'alpha_100': ('STD2(VOLUME_DF, 20)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.043\n",
    "\n",
    "# factor_def_dict = {'alpha_103': ('((20 - LOWDAY(LOW_DF, 20)) / 20) * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.019\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_104': ('-1 * (DELTA(CORR(HIGH_DF, VOLUME_DF, 5), 5) * RANK(STD2(CLOSE_DF, 20)))', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.013\n",
    "\n",
    "# factor_def_dict = {'alpha_105': ('(-1 * CORR(RANK(OPEN_DF), RANK(VOLUME_DF), 10)) ', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.022\n",
    "\n",
    "# factor_def_dict = {'alpha_106': ('CLOSE_DF - DELAY(CLOSE_DF, 20)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.044\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_107': ('(((-1 * RANK((OPEN_DF - DELAY(HIGH_DF, 1)))) * RANK((OPEN_DF - DELAY(CLOSE_DF, 1)))) * RANK((OPEN_DF - DELAY(LOW_DF, 1))))', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.028\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_110': ('SUM(HIGH_DF - OPEN_DF, 20) / SUM(OPEN_DF - LOW_DF, 20) * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.055\n",
    "\n",
    "# factor_def_dict = {'alpha_126': ('(CLOSE_DF + HIGH_DF + LOW_DF) / 3', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.046\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_133': ('((20-HIGHDAY(HIGH_DF, 20)) / 20) * 100 - ((20 - LOWDAY(LOW, 20)) / 20) * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_134': ('(CLOSE_DF - DELAY(CLOSE_DF, 12)) / DELAY(CLOSE_DF, 12) * VOLUME_DF', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_139': ('(-1 * CORR(OPEN_DF, VOLUME_DF, 10))', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_150': ('(CLOSE_DF + HIGH_DF + LOW_DF) / 3 * VOLUME_DF', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_153': ('(MEAN(CLOSE_DF, 3) + MEAN(CLOSE_DF, 6) + MEAN(CLOSE_DF, 12) + MEAN(CLOSE_DF, 24)) / 4', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_168': ('(-1 * VOLUME_DF / MEAN(VOLUME_DF, 20))', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_175': ('MEAN(MAX(MAX((HIGH_DF - LOW_DF), ABS(DELAY(CLOSE_DF, 1) - HIGH_DF)), ABS(DELAY(CLOSE_DF, 1) - LOW_DF)), 6)', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_177': ('((20 - HIGHDAY(HIGH_DF, 20)) / 20) * 100', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_178': ('(CLOSE_DF - DELAY(CLOSE_DF, 1)) / DELAY(CLOSE_DF, 1) * VOLUME_DF', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0\n",
    "\n",
    "# factor_def_dict = \\\n",
    "# {'alpha_184': ('(RANK(CORR(DELAY((OPEN_DF - CLOSE_DF), 1), CLOSE_DF, 200)) + RANK((OPEN_DF - CLOSE_DF)))', 22)}\n",
    "# total loss = 0.011\n",
    "# IC mean = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d80e49-1343-4352-bd3c-8d075ffb7c81",
   "metadata": {},
   "source": [
    "#### 运行以下单元格衡量因子整体的覆盖率和IC表现,不要自行修改以下代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "8d77a673-741e-4c5d-84c9-acb43e6e2a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open', 'volume', 'close']"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_factors = get_needing_basic_factors(str(factor_def_dict))\n",
    "basic_factors = [x[:-3].lower() for x in basic_factors]\n",
    "if 'close' not in basic_factors:\n",
    "    basic_factors.append('close')\n",
    "basic_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "5b037cfd-0cef-4993-84ea-f46c66606f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>buy_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade_date</th>\n",
       "      <th>ts_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-01-04</th>\n",
       "      <th>000001.SZ</th>\n",
       "      <td>16.48</td>\n",
       "      <td>1169260.00</td>\n",
       "      <td>16.66</td>\n",
       "      <td>16.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000002.SZ</th>\n",
       "      <td>19.49</td>\n",
       "      <td>1947200.00</td>\n",
       "      <td>20.49</td>\n",
       "      <td>20.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000004.SZ</th>\n",
       "      <td>19.41</td>\n",
       "      <td>46185.90</td>\n",
       "      <td>19.99</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000005.SZ</th>\n",
       "      <td>2.30</td>\n",
       "      <td>146240.00</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000006.SZ</th>\n",
       "      <td>4.45</td>\n",
       "      <td>127024.00</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023-12-08</th>\n",
       "      <th>688799.SH</th>\n",
       "      <td>44.00</td>\n",
       "      <td>3803.73</td>\n",
       "      <td>43.75</td>\n",
       "      <td>43.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688800.SH</th>\n",
       "      <td>44.24</td>\n",
       "      <td>15357.00</td>\n",
       "      <td>42.76</td>\n",
       "      <td>42.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688819.SH</th>\n",
       "      <td>28.50</td>\n",
       "      <td>37841.60</td>\n",
       "      <td>29.15</td>\n",
       "      <td>29.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688981.SH</th>\n",
       "      <td>52.67</td>\n",
       "      <td>381398.00</td>\n",
       "      <td>52.55</td>\n",
       "      <td>52.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689009.SH</th>\n",
       "      <td>33.00</td>\n",
       "      <td>196129.00</td>\n",
       "      <td>33.58</td>\n",
       "      <td>33.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2279140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       OPEN      VOLUME  CLOSE  buy_price\n",
       "trade_date ts_code                                       \n",
       "2022-01-04 000001.SZ  16.48  1169260.00  16.66      16.66\n",
       "           000002.SZ  19.49  1947200.00  20.49      20.49\n",
       "           000004.SZ  19.41    46185.90  19.99      19.99\n",
       "           000005.SZ   2.30   146240.00   2.36       2.36\n",
       "           000006.SZ   4.45   127024.00   4.53       4.53\n",
       "...                     ...         ...    ...        ...\n",
       "2023-12-08 688799.SH  44.00     3803.73  43.75      43.75\n",
       "           688800.SH  44.24    15357.00  42.76      42.76\n",
       "           688819.SH  28.50    37841.60  29.15      29.15\n",
       "           688981.SH  52.67   381398.00  52.55      52.55\n",
       "           689009.SH  33.00   196129.00  33.58      33.58\n",
       "\n",
       "[2279140 rows x 4 columns]"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ori_factor = get_list_factors(basic_factors, start_date='20220101', end_date = '20231230')\n",
    "ori_factor = pd.read_csv('ori_factor_test.csv',\n",
    "                         parse_dates=['trade_date'],\n",
    "                         index_col=[\"trade_date\", \"ts_code\"])\n",
    "ori_factor = ori_factor[basic_factors]\n",
    "ori_factor.columns = [x.upper() for x in ori_factor.columns]\n",
    "ori_factor = ori_factor.sort_index(ascending=True)\n",
    "ori_factor['buy_price'] = ori_factor['CLOSE']\n",
    "ori_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "86383064-5400-4543-acd3-400b9dd48568",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:08<00:00, 68.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "factor_eval_dict = {}\n",
    "for factor_name in tqdm.tqdm(factor_def_dict):\n",
    "    factor_exp = factor_def_dict[factor_name][0] # type: ignore\n",
    "    factor_need_days = factor_def_dict[factor_name][1] # type: ignore\n",
    "    f, d = exec_and_eval_exp(factor_exp=factor_exp,\n",
    "                            need_days=factor_need_days,\n",
    "                            quantiles=None,\n",
    "                            bins=10,\n",
    "                            original_data=ori_factor,\n",
    "                            max_loss=0.5)\n",
    "    factor_eval_dict = factor_eval_dict.copy()  # 创建一个新的字典副本\n",
    "    factor_eval_dict[factor_name] = d\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha_01': {'tot_loss': 0.011371210564405886,\n",
       "  'fwdret_loss': 0.011371210564405886,\n",
       "  'bin_loss': 0.0,\n",
       "  'quantile_stats':                       min       max      mean       std   count    count %\n",
       "  factor_quantile                                                           \n",
       "  1               -0.999544 -0.738134 -0.868224  0.052989   65851   2.975636\n",
       "  2               -0.799867 -0.543790 -0.684216  0.057514  126500   5.716207\n",
       "  3               -0.601642 -0.352536 -0.487701  0.057764  168108   7.596364\n",
       "  4               -0.403342 -0.159142 -0.289729  0.057716  205767   9.298077\n",
       "  5               -0.205671  0.032936 -0.092072  0.057580  244673  11.056138\n",
       "  6               -0.007517  0.225264  0.105240  0.057383  279635  12.635980\n",
       "  7                0.187601  0.417637  0.302674  0.057410  302711  13.678725\n",
       "  8                0.382960  0.609799  0.500044  0.057348  312860  14.137332\n",
       "  9                0.578212  0.803639  0.696491  0.057046  303670  13.722059\n",
       "  10               0.773730  0.999629  0.878290  0.051966  203231   9.183482,\n",
       "  'returns_table':                                                   1D     3D     5D\n",
       "  Ann. alpha                                    -0.032 -0.029 -0.019\n",
       "  beta                                          -0.018 -0.004  0.006\n",
       "  Mean Period Wise Return Top Quantile (bps)    -5.125 -4.639 -3.707\n",
       "  Mean Period Wise Return Bottom Quantile (bps)  2.278  1.880  0.345\n",
       "  Mean Period Wise Spread (bps)                 -7.402 -6.505 -4.034,\n",
       "  'ic_summary_table':                      1D     3D     5D\n",
       "  IC Mean          -0.024 -0.025 -0.023\n",
       "  IC Std.           0.080  0.077  0.076\n",
       "  Risk-Adjusted IC -0.295 -0.319 -0.304\n",
       "  t-stat(IC)       -6.308 -6.825 -6.500\n",
       "  p-value(IC)       0.000  0.000  0.000\n",
       "  IC Skew           0.096  0.182  0.125\n",
       "  IC Kurtosis      -0.090 -0.129 -0.226,\n",
       "  'turnover_table':                                1D     3D     5D\n",
       "  Quantile 1 Mean Turnover    0.538  0.848  0.943\n",
       "  Quantile 2 Mean Turnover    0.628  0.843  0.915\n",
       "  Quantile 3 Mean Turnover    0.688  0.855  0.903\n",
       "  Quantile 4 Mean Turnover    0.719  0.858  0.893\n",
       "  Quantile 5 Mean Turnover    0.728  0.858  0.883\n",
       "  Quantile 6 Mean Turnover    0.720  0.848  0.871\n",
       "  Quantile 7 Mean Turnover    0.697  0.835  0.860\n",
       "  Quantile 8 Mean Turnover    0.650  0.812  0.846\n",
       "  Quantile 9 Mean Turnover    0.556  0.763  0.831\n",
       "  Quantile 10 Mean Turnover   0.411  0.714  0.853,\n",
       "  'auto_corr':                                      1D     3D     5D\n",
       "  Mean Factor Rank Autocorrelation  0.816  0.479  0.182}}"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_eval_dict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea5254b8",
   "metadata": {},
   "source": [
    "{'alpha191_022': {'tot_loss': 0.011639023813159347,\n",
    "  'fwdret_loss': 0.011639023813159347,\n",
    "  'bin_loss': 0.0,\n",
    "  'quantile_stats':                       min       max      mean       std   count    count %\n",
    "  factor_quantile                                                           \n",
    "  1               -0.209784 -0.029960 -0.074159  0.026069    1503   0.069730\n",
    "  2               -0.163690 -0.017243 -0.047609  0.016715    4052   0.187987\n",
    "  3               -0.142772  0.001447 -0.021276  0.015188   29795   1.382297\n",
    "  4               -0.097721  0.026761 -0.007052  0.010915  224601  10.420048\n",
    "  5               -0.082798  0.054203 -0.002659  0.009477  577301  26.783068\n",
    "  6               -0.065968  0.077976  0.000454  0.008561  794941  36.880170\n",
    "  7               -0.038355  0.100337  0.005800  0.008926  432997  20.088287\n",
    "  8               -0.012624  0.131858  0.013076  0.012852   80583   3.738535\n",
    "  9                0.004293  0.160261  0.034235  0.015915    7799   0.361824\n",
    "  10               0.021584  0.220041  0.061170  0.024453    1898   0.088055,\n",
    "  'returns_table':                                                    1D      3D      5D\n",
    "  Ann. alpha                                     -0.032  -0.065  -0.053\n",
    "  beta                                           -0.092  -0.049  -0.023\n",
    "  Mean Period Wise Return Top Quantile (bps)     67.510  17.577   2.027\n",
    "  Mean Period Wise Return Bottom Quantile (bps) -22.926 -17.720 -18.337\n",
    "  Mean Period Wise Spread (bps)                  90.436  30.830  14.315,\n",
    "  'ic_summary_table':                      1D     3D     5D\n",
    "  IC Mean          -0.016 -0.020 -0.022\n",
    "  IC Std.           0.125  0.120  0.119\n",
    "  Risk-Adjusted IC -0.131 -0.165 -0.182\n",
    "  t-stat(IC)       -2.769 -3.469 -3.829\n",
    "  p-value(IC)       0.006  0.001  0.000\n",
    "  IC Skew           0.074 -0.056 -0.026\n",
    "  IC Kurtosis      -0.029  0.171 -0.218,\n",
    "  'turnover_table':                                1D     3D     5D\n",
    "  Quantile 1 Mean Turnover    0.382  0.866  0.974\n",
    "  Quantile 2 Mean Turnover    0.686  0.915  0.962\n",
    "  Quantile 3 Mean Turnover    0.645  0.880  0.937\n",
    "  Quantile 4 Mean Turnover    0.577  0.805  0.869\n",
    "  Quantile 5 Mean Turnover    0.502  0.692  0.726\n",
    "  Quantile 6 Mean Turnover    0.466  0.620  0.637\n",
    "  Quantile 7 Mean Turnover    0.524  0.733  0.799\n",
    "  Quantile 8 Mean Turnover    0.612  0.878  0.940\n",
    "  Quantile 9 Mean Turnover    0.675  0.914  0.972\n",
    "  Quantile 10 Mean Turnover   0.422  0.885  0.978,\n",
    "  'auto_corr':                                      1D     3D     5D\n",
    "  Mean Factor Rank Autocorrelation  0.863  0.342  0.041}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "5114c1bb-cb9d-4558-995a-8df31eb1bf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 659.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss = 0.011371210564405886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "factor_score_list = []\n",
    "for factor_name in tqdm.tqdm(factor_def_dict):\n",
    "    tot_loss = factor_eval_dict[factor_name]['tot_loss']\n",
    "    print(f\"Total loss = {tot_loss}\")\n",
    "    loss_score = 1 if tot_loss < 0.1 else 0   #因子覆盖率需要大于90%\n",
    "    \n",
    "    ic_score = abs(factor_eval_dict[factor_name]['ic_summary_table'].loc['IC Mean', :]).mean()  #因子IC\n",
    "    factor_score = loss_score * ic_score\n",
    "    factor_score_list.append(factor_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be34aa",
   "metadata": {},
   "source": [
    "#### An example in Python to illustrate the concept of factor coverage ratio.\n",
    "\n",
    "Suppose we have a portfolio consisting of 10 stocks, and we are using a factor model to measure the returns of these stocks. Taking the Market Value factor as an example, we want to use it to explain the returns of these stocks.\n",
    "\n",
    "Firstly, we need to calculate the Market Value factor values for each stock and store them in a list called \"market_value_factor\".\n",
    "\n",
    "Next, we can use the following Python code to calculate the factor coverage ratio:\n",
    "\n",
    "```python\n",
    "# Assuming the market value factor values are [0, 1.2, 0.9, 1.5, 1.0, 1.3, 0.7, 1.1, 0.6, 1.4]\n",
    "market_value_factor = [0, 1.2, 0.9, 1.5, 1.0, 1.3, 0.7, 1.1, 0.6, 1.4]\n",
    "\n",
    "# Calculate the factor coverage ratio\n",
    "num_stocks = len(market_value_factor)  # Number of stocks\n",
    "covered_stocks = sum(1 for factor in market_value_factor if factor != 0)  # Number of stocks covered by the factor\n",
    "\n",
    "factor_coverage_ratio = covered_stocks / num_stocks * 100  # Factor coverage ratio in percentage\n",
    "\n",
    "print(\"Factor Coverage Ratio: {:.2f}%\".format(factor_coverage_ratio))\n",
    "\n",
    "# Factor Coverage Ratio: 90.00%\n",
    "```\n",
    "\n",
    "By running the above code, it will output the factor coverage ratio as a percentage. For example, if the factor covers 8 out of 10 stocks, the factor coverage ratio will be 80%.\n",
    "\n",
    "In this example, we used the Market Value factor to explain the returns of the stocks in the portfolio and calculated the coverage ratio of the factor. This helps us assess the explanatory power and predictive accuracy of the factor model for the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.024000000000000004]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024000000000000004"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval_value > 0.015\n",
    "eval_value = sum(factor_score_list) / len(factor_score_list)\n",
    "eval_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
