{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HS300 backtest\n",
    "1. Data collection: HS300.\n",
    "2. Data cleaning: Remove stocks with missing value.\n",
    "3. Label making: VWAP ROI of between T and T + 11.\n",
    "4. Data preprocessing: 3MAD, z-score etc.\n",
    "5. ROI dataframe making: HS300, CS500, CS1000 etc.\n",
    "6. Modeling: MLP, GBDT, GRU, AGRU. *(Rolling position adjustment)*\n",
    "7. Ensembling: according to past 60 days' ICIR.\n",
    "8. Backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Attention, Layer, GRU, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from datetime import date, timedelta\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# Get the current process ID of the IPython kernel\n",
    "pid = os.getpid()\n",
    "# Get the process associated with the IPython kernel\n",
    "process = psutil.Process(pid)\n",
    "\n",
    "from cylib.apis.all_api import *\n",
    "import baostock as bs\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress the warning\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=pd.core.common.SettingWithCopyWarning)\n",
    "\n",
    "zscore = StandardScaler()\n",
    "\n",
    "# Suppress the warning\n",
    "# warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "Main_bactest = False\n",
    "Online = True\n",
    "path = \"/home/huh/Stage-2/HS300-Single/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stocks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor_name</th>\n",
       "      <th>describe</th>\n",
       "      <th>need_days</th>\n",
       "      <th>contributor</th>\n",
       "      <th>calc_type</th>\n",
       "      <th>data_type</th>\n",
       "      <th>from</th>\n",
       "      <th>now_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adj_close</td>\n",
       "      <td>复权收盘价(元)</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adj_factor</td>\n",
       "      <td>复权因子</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adj_high</td>\n",
       "      <td>复权最高价(元)</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adj_high_52w</td>\n",
       "      <td>52周最高价(复权)</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj_low</td>\n",
       "      <td>复权最低价(元)</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tot_shr</td>\n",
       "      <td>当日总股本</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>trade_status</td>\n",
       "      <td>交易状态</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>turn</td>\n",
       "      <td>换手率</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>up_down_limit_status</td>\n",
       "      <td>涨跌停状态</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>volume</td>\n",
       "      <td>成交量(手)</td>\n",
       "      <td>1</td>\n",
       "      <td>market</td>\n",
       "      <td>daily_spider</td>\n",
       "      <td>float</td>\n",
       "      <td>market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              factor_name    describe  need_days contributor     calc_type  \\\n",
       "0               adj_close    复权收盘价(元)          1      market  daily_spider   \n",
       "1              adj_factor        复权因子          1      market  daily_spider   \n",
       "2                adj_high    复权最高价(元)          1      market  daily_spider   \n",
       "3            adj_high_52w  52周最高价(复权)          1      market  daily_spider   \n",
       "4                 adj_low    复权最低价(元)          1      market  daily_spider   \n",
       "..                    ...         ...        ...         ...           ...   \n",
       "313               tot_shr       当日总股本          1      market  daily_spider   \n",
       "314          trade_status        交易状态          1      market  daily_spider   \n",
       "315                  turn         换手率          1      market  daily_spider   \n",
       "316  up_down_limit_status       涨跌停状态          1      market  daily_spider   \n",
       "317                volume      成交量(手)          1      market  daily_spider   \n",
       "\n",
       "    data_type    from  now_available  \n",
       "0       float  market              1  \n",
       "1       float  market              1  \n",
       "2       float  market              1  \n",
       "3       float  market              1  \n",
       "4       float  market              1  \n",
       "..        ...     ...            ...  \n",
       "313     float  market              1  \n",
       "314     float  market              1  \n",
       "315     float  market              1  \n",
       "316     float  market              1  \n",
       "317     float  market              1  \n",
       "\n",
       "[318 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain HS300 index\n",
    "lg = bs.login()\n",
    "rs = bs.query_hs300_stocks()\n",
    "hs300_stocks = []\n",
    "while (rs.error_code == \"0\") & rs.next():\n",
    "    hs300_stocks.append(rs.get_row_data())\n",
    "hs300_stocks = pd.DataFrame(hs300_stocks)\n",
    "HS300 = list(hs300_stocks[1])\n",
    "HS300 = [HS300[i][-6:] + \".\" + HS300[i][:2].upper() for i in range(len(HS300))]\n",
    "stocks_code = HS300\n",
    "\n",
    "all_stocks = get_targets_info(target_type=\"stock\")\n",
    "# all_stocks.to_csv(path + 'all_stocks.csv', index=False)\n",
    "\n",
    "factor_info = get_factors_info()\n",
    "factor_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha101_001',\n",
       " 'alpha101_002',\n",
       " 'alpha101_003',\n",
       " 'alpha101_004',\n",
       " 'alpha101_005',\n",
       " 'alpha101_006',\n",
       " 'alpha101_007',\n",
       " 'alpha101_008',\n",
       " 'alpha101_009',\n",
       " 'alpha101_010',\n",
       " 'alpha101_011',\n",
       " 'alpha101_012',\n",
       " 'alpha101_013',\n",
       " 'alpha101_014',\n",
       " 'alpha101_015',\n",
       " 'alpha101_016',\n",
       " 'alpha101_017',\n",
       " 'alpha101_018',\n",
       " 'alpha101_019',\n",
       " 'alpha101_020',\n",
       " 'alpha101_021',\n",
       " 'alpha101_022',\n",
       " 'alpha101_023',\n",
       " 'alpha101_024',\n",
       " 'alpha101_025',\n",
       " 'alpha101_026',\n",
       " 'alpha101_027',\n",
       " 'alpha101_028',\n",
       " 'alpha101_029',\n",
       " 'alpha101_030',\n",
       " 'alpha101_031',\n",
       " 'alpha101_032',\n",
       " 'alpha101_033',\n",
       " 'alpha101_034',\n",
       " 'alpha101_035',\n",
       " 'alpha101_037',\n",
       " 'alpha101_038',\n",
       " 'alpha101_039',\n",
       " 'alpha101_040',\n",
       " 'alpha101_041',\n",
       " 'alpha101_042',\n",
       " 'alpha101_043',\n",
       " 'alpha101_044',\n",
       " 'alpha101_045',\n",
       " 'alpha101_046',\n",
       " 'alpha101_047',\n",
       " 'alpha101_049',\n",
       " 'alpha101_050',\n",
       " 'alpha101_051',\n",
       " 'alpha101_052',\n",
       " 'alpha101_053',\n",
       " 'alpha101_054',\n",
       " 'alpha101_055',\n",
       " 'alpha101_057',\n",
       " 'alpha101_060',\n",
       " 'alpha101_061',\n",
       " 'alpha101_062',\n",
       " 'alpha101_064',\n",
       " 'alpha101_065',\n",
       " 'alpha101_066',\n",
       " 'alpha101_068',\n",
       " 'alpha101_071',\n",
       " 'alpha101_072',\n",
       " 'alpha101_073',\n",
       " 'alpha101_074',\n",
       " 'alpha101_075',\n",
       " 'alpha101_077',\n",
       " 'alpha101_078',\n",
       " 'alpha101_081',\n",
       " 'alpha101_083',\n",
       " 'alpha101_084',\n",
       " 'alpha101_085',\n",
       " 'alpha101_086',\n",
       " 'alpha101_088',\n",
       " 'alpha101_092',\n",
       " 'alpha101_094',\n",
       " 'alpha101_095',\n",
       " 'alpha101_096',\n",
       " 'alpha101_098',\n",
       " 'alpha101_099',\n",
       " 'alpha101_101',\n",
       " 'alpha191_001',\n",
       " 'alpha191_002',\n",
       " 'alpha191_003',\n",
       " 'alpha191_004',\n",
       " 'alpha191_005',\n",
       " 'alpha191_006',\n",
       " 'alpha191_007',\n",
       " 'alpha191_008',\n",
       " 'alpha191_009',\n",
       " 'alpha191_010',\n",
       " 'alpha191_011',\n",
       " 'alpha191_012',\n",
       " 'alpha191_013',\n",
       " 'alpha191_014',\n",
       " 'alpha191_015',\n",
       " 'alpha191_016',\n",
       " 'alpha191_017',\n",
       " 'alpha191_018',\n",
       " 'alpha191_019',\n",
       " 'alpha191_020',\n",
       " 'alpha191_021',\n",
       " 'alpha191_022',\n",
       " 'alpha191_023',\n",
       " 'alpha191_024',\n",
       " 'alpha191_025',\n",
       " 'alpha191_026',\n",
       " 'alpha191_027',\n",
       " 'alpha191_028',\n",
       " 'alpha191_029',\n",
       " 'alpha191_030',\n",
       " 'alpha191_031',\n",
       " 'alpha191_032',\n",
       " 'alpha191_033',\n",
       " 'alpha191_034',\n",
       " 'alpha191_035',\n",
       " 'alpha191_036',\n",
       " 'alpha191_037',\n",
       " 'alpha191_038',\n",
       " 'alpha191_039',\n",
       " 'alpha191_040',\n",
       " 'alpha191_041',\n",
       " 'alpha191_042',\n",
       " 'alpha191_043',\n",
       " 'alpha191_044',\n",
       " 'alpha191_045',\n",
       " 'alpha191_046',\n",
       " 'alpha191_047',\n",
       " 'alpha191_048',\n",
       " 'alpha191_049',\n",
       " 'alpha191_050',\n",
       " 'alpha191_051',\n",
       " 'alpha191_052',\n",
       " 'alpha191_053',\n",
       " 'alpha191_054',\n",
       " 'alpha191_055',\n",
       " 'alpha191_056',\n",
       " 'alpha191_057',\n",
       " 'alpha191_058',\n",
       " 'alpha191_059',\n",
       " 'alpha191_060',\n",
       " 'alpha191_061',\n",
       " 'alpha191_062',\n",
       " 'alpha191_063',\n",
       " 'alpha191_064',\n",
       " 'alpha191_065',\n",
       " 'alpha191_066',\n",
       " 'alpha191_067',\n",
       " 'alpha191_068',\n",
       " 'alpha191_069',\n",
       " 'alpha191_070',\n",
       " 'alpha191_071',\n",
       " 'alpha191_072',\n",
       " 'alpha191_073',\n",
       " 'alpha191_074',\n",
       " 'alpha191_075',\n",
       " 'alpha191_076',\n",
       " 'alpha191_077',\n",
       " 'alpha191_078',\n",
       " 'alpha191_079',\n",
       " 'alpha191_080',\n",
       " 'alpha191_081',\n",
       " 'alpha191_082',\n",
       " 'alpha191_083',\n",
       " 'alpha191_084',\n",
       " 'alpha191_085',\n",
       " 'alpha191_086',\n",
       " 'alpha191_087',\n",
       " 'alpha191_088',\n",
       " 'alpha191_089',\n",
       " 'alpha191_090',\n",
       " 'alpha191_091',\n",
       " 'alpha191_092',\n",
       " 'alpha191_093',\n",
       " 'alpha191_094',\n",
       " 'alpha191_095',\n",
       " 'alpha191_096',\n",
       " 'alpha191_097',\n",
       " 'alpha191_098',\n",
       " 'alpha191_099',\n",
       " 'alpha191_100',\n",
       " 'alpha191_101',\n",
       " 'alpha191_102',\n",
       " 'alpha191_103',\n",
       " 'alpha191_104',\n",
       " 'alpha191_105',\n",
       " 'alpha191_106',\n",
       " 'alpha191_107',\n",
       " 'alpha191_108',\n",
       " 'alpha191_109',\n",
       " 'alpha191_110',\n",
       " 'alpha191_111',\n",
       " 'alpha191_112',\n",
       " 'alpha191_113',\n",
       " 'alpha191_114',\n",
       " 'alpha191_115',\n",
       " 'alpha191_116',\n",
       " 'alpha191_117',\n",
       " 'alpha191_118',\n",
       " 'alpha191_119',\n",
       " 'alpha191_120',\n",
       " 'alpha191_121',\n",
       " 'alpha191_122',\n",
       " 'alpha191_123',\n",
       " 'alpha191_124',\n",
       " 'alpha191_125',\n",
       " 'alpha191_126',\n",
       " 'alpha191_127',\n",
       " 'alpha191_128',\n",
       " 'alpha191_129',\n",
       " 'alpha191_130',\n",
       " 'alpha191_131',\n",
       " 'alpha191_132',\n",
       " 'alpha191_133',\n",
       " 'alpha191_134',\n",
       " 'alpha191_135',\n",
       " 'alpha191_136',\n",
       " 'alpha191_137',\n",
       " 'alpha191_138',\n",
       " 'alpha191_139',\n",
       " 'alpha191_140',\n",
       " 'alpha191_141',\n",
       " 'alpha191_142',\n",
       " 'alpha191_143',\n",
       " 'alpha191_144',\n",
       " 'alpha191_145',\n",
       " 'alpha191_146',\n",
       " 'alpha191_147',\n",
       " 'alpha191_148',\n",
       " 'alpha191_150',\n",
       " 'alpha191_151',\n",
       " 'alpha191_152',\n",
       " 'alpha191_153',\n",
       " 'alpha191_154',\n",
       " 'alpha191_155',\n",
       " 'alpha191_156',\n",
       " 'alpha191_157',\n",
       " 'alpha191_158',\n",
       " 'alpha191_159',\n",
       " 'alpha191_160',\n",
       " 'alpha191_161',\n",
       " 'alpha191_163',\n",
       " 'alpha191_164',\n",
       " 'alpha191_165',\n",
       " 'alpha191_166',\n",
       " 'alpha191_167',\n",
       " 'alpha191_168',\n",
       " 'alpha191_169',\n",
       " 'alpha191_170',\n",
       " 'alpha191_171',\n",
       " 'alpha191_172',\n",
       " 'alpha191_173',\n",
       " 'alpha191_174',\n",
       " 'alpha191_175',\n",
       " 'alpha191_176',\n",
       " 'alpha191_177',\n",
       " 'alpha191_178',\n",
       " 'alpha191_179',\n",
       " 'alpha191_180',\n",
       " 'alpha191_181',\n",
       " 'alpha191_182',\n",
       " 'alpha191_183',\n",
       " 'alpha191_184',\n",
       " 'alpha191_185',\n",
       " 'alpha191_187',\n",
       " 'alpha191_188',\n",
       " 'alpha191_189',\n",
       " 'alpha191_190',\n",
       " 'alpha191_191']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors_name = list(factor_info[factor_info['from'] == 'article']['factor_name'])\n",
    "factors_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factors_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HS300_Single():\n",
    "    def __init__(self, Factor_Name, Begin_Date, End_Date, Stocks_Code) -> None:\n",
    "        print(f\"Factor: {Factor_Name}\")\n",
    "        self.factor_name = Factor_Name\n",
    "        self.begin_date = Begin_Date\n",
    "        self.end_date = End_Date\n",
    "        self.stocks_code = Stocks_Code\n",
    "        self.Get_Trade_Calendar()\n",
    "        self.Data()\n",
    "        # self.Get_Benchmark()\n",
    "        self.Get_Daily_Return()\n",
    "        self.Factor_DF()\n",
    "        # self.Backtest_Main()\n",
    "        # self.Backtest_Simple(6, False)\n",
    "        # self.Indexes()\n",
    "    def RAM_USAGE(self):\n",
    "        # Get the memory usage of the IPython kernel in MB\n",
    "        ram_usage = process.memory_info().rss / (1024 * 1024)\n",
    "        print(f\"RAM Usage: {ram_usage} MB\")\n",
    "    def Get_Trade_Calendar(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Getting trade calendar...\")\n",
    "        PRICE = get_factor(self.factor_name, \n",
    "                           start_date=self.begin_date, \n",
    "                           end_date=self.end_date, \n",
    "                           ts_code_list=self.stocks_code)\n",
    "        PRICE.reset_index(inplace=True)\n",
    "        PRICE = PRICE.sort_values(by=\"trade_date\").reset_index(drop=True)\n",
    "        # price.set_index(['trade_date', 'ts_code'], inplace=True)\n",
    "        PRICE = PRICE.fillna(0)\n",
    "        PRICE = PRICE.drop_duplicates(subset=['trade_date', 'ts_code'])\n",
    "        PRICE_pivot = PRICE.pivot(index=\"trade_date\", \n",
    "                                  columns=\"ts_code\", \n",
    "                                  values=self.factor_name)\n",
    "\n",
    "        # Attention: len(date_all) >= 60\n",
    "        date_all = PRICE_pivot.index\n",
    "        self.date_all = date_all\n",
    "        # _, date_backtest = train_test_split(date_all, test_size=0.2, shuffle=False)\n",
    "        # backtest_begin = date_backtest[0]\n",
    "        # backtest_end = date_backtest[-1]\n",
    "\n",
    "        # Find missing stocks\n",
    "        all_combinations = pd.MultiIndex.from_product(\n",
    "            [date_all, stocks_code], \n",
    "            names=[\"trade_date\", \"ts_code\"])\n",
    "        all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "        price_whole = pd.merge(\n",
    "            all_combinations_df, \n",
    "            PRICE, \n",
    "            on=[\"trade_date\", \"ts_code\"], \n",
    "            how=\"left\")\n",
    "        missing = price_whole[price_whole.isnull().any(axis=1)]\n",
    "        missing_stock = missing[\"ts_code\"].unique()\n",
    "        print(\"The missing stock:\", missing_stock)\n",
    "\n",
    "        self.stocks_code = list(set(HS300) - set(missing_stock))\n",
    "        print(\"*\" * 60)\n",
    "    def Data(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Get data...\")\n",
    "        # Get factor\n",
    "        factor = get_factor(self.factor_name, \n",
    "                        start_date=self.begin_date, \n",
    "                        end_date=self.end_date, \n",
    "                        ts_code_list=self.stocks_code)\n",
    "        factor.reset_index(inplace=True)\n",
    "        factor = factor.drop_duplicates(subset=['trade_date', 'ts_code'])\n",
    "        self.factor = factor.sort_values(by=\"trade_date\").reset_index(drop=True)\n",
    "\n",
    "        # Get stocks\n",
    "        price = get_price(\n",
    "            ts_code_list=self.stocks_code,\n",
    "            feature_list=[\n",
    "                \"open\",\n",
    "                \"close\"\n",
    "            ],\n",
    "            start_date=self.begin_date,\n",
    "            trade_date=self.end_date,\n",
    "            target_type=\"stock\",\n",
    "        )\n",
    "        price = price.rename(\n",
    "            columns={\n",
    "                \"open\": \"OPEN\",\n",
    "                \"close\": \"CLOSE\"\n",
    "            }\n",
    "        )\n",
    "        price.reset_index(inplace=True)\n",
    "        # Add weekend, If it is Monday, the value is 1, or 0.\n",
    "        # price['Monday'] = (price['trade_date'].dt.dayofweek == 0).astype(int)\n",
    "        self.price = price.sort_values(by=\"trade_date\").reset_index(drop=True)\n",
    "        # price.set_index(['trade_date', 'ts_code'], inplace=True)\n",
    "        # price.fillna(0, inplace=True)\n",
    "        self.RAM_USAGE()\n",
    "        print(\"*\" * 60)\n",
    "    def Get_Benchmark(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Get benchmark...\")\n",
    "        # Get benchmark index\n",
    "        # 1. the Shanghai and Shenzhen 300 index(the HS 300 index)(000300)\n",
    "        # 2. the China Securities 500 index(000905)\n",
    "        # 3. the China Securities 1000 index(000852)\n",
    "        benchmark = get_price(\n",
    "            ts_code_list=[\"000300.SH\", \"000905.SH\", \"000852.SH\"],\n",
    "            feature_list=[\"open\", \"close\"],\n",
    "            start_date=self.begin_date,\n",
    "            trade_date=self.end_date,\n",
    "            target_type=\"index\",\n",
    "        )\n",
    "        benchmark = benchmark.rename(\n",
    "            columns={\n",
    "                \"open\": \"OPEN\",\n",
    "                \"close\": \"CLOSE\"\n",
    "            }\n",
    "        )\n",
    "        benchmark.reset_index(inplace=True)\n",
    "        # Add weekend, If it is Monday, the value is 1, or 0.\n",
    "        # benchmark[\"Monday\"] = (benchmark[\"trade_date\"].dt.dayofweek == 0).astype(int)\n",
    "        benchmark = benchmark.sort_values(by=\"trade_date\").reset_index(drop=True)\n",
    "        benchmark.fillna(0, inplace=True)\n",
    "        self.benchmark = benchmark\n",
    "        self.RAM_USAGE()\n",
    "        print(\"*\" * 60)\n",
    "    def Get_Daily_Return(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Get daily return...\")\n",
    "        price = self.price\n",
    "        benchmark = self.benchmark\n",
    "        BUY_price = price.pivot(index=\"trade_date\", columns=\"ts_code\", values=\"OPEN\")\n",
    "        BUY_benchmark = benchmark.pivot(index=\"trade_date\", columns=\"ts_code\", values=\"OPEN\")\n",
    "        SELL_price = price.pivot(index=\"trade_date\", columns=\"ts_code\", values=\"CLOSE\")\n",
    "        SELL_benchmark = benchmark.pivot(index=\"trade_date\", columns=\"ts_code\", values=\"CLOSE\")\n",
    "        price_return = (SELL_price - BUY_price) / BUY_price\n",
    "        self.price_return = price_return.loc[price_return.index.isin(self.date_all), :]\n",
    "        benchmark_return = (SELL_benchmark - BUY_benchmark) / BUY_benchmark\n",
    "        self.benchmark_return = benchmark_return.loc[benchmark_return.index.isin(self.date_all), :]\n",
    "\n",
    "        self.HS_300 = pd.DataFrame(benchmark_return[\"000300.SH\"])[\"000300.SH\"]\n",
    "        self.CS_500 = pd.DataFrame(benchmark_return[\"000905.SH\"])[\"000905.SH\"]\n",
    "        self.CS_1000 = pd.DataFrame(benchmark_return[\"000852.SH\"])[\"000852.SH\"]\n",
    "        print(\"*\" * 60)\n",
    "    def Data_preprocessing(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Data preprocessing...\")\n",
    "        factor = self.factor\n",
    "        # Data preprocessing\n",
    "        def value_mapping(row):\n",
    "            return value_dict[row[\"trade_date\"]][row[\"ts_code\"]]\n",
    "\n",
    "        # 3MAD\n",
    "        def Col_3MAD(row):\n",
    "            median = row.median()  # median\n",
    "            mad = abs(row - row.median()).median()\n",
    "            threshold = 3 * mad\n",
    "            lower_bound = median - threshold\n",
    "            upper_bound = median + threshold\n",
    "            return row.clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "        indexes = [self.factor_name]\n",
    "        for index in indexes:\n",
    "            df = factor.pivot(index=\"trade_date\", columns=\"ts_code\", values=index)\n",
    "            values = df.values\n",
    "            # Standardize for each row\n",
    "            df = pd.DataFrame(zscore.fit_transform(values.T).T, index=df.index, columns=df.columns)\n",
    "            df = df.apply(Col_3MAD, axis=1)  # 3 times MAD for each row\n",
    "            value_dict = df.to_dict(orient=\"index\")\n",
    "            factor[index + \"_processed\"] = factor.apply(value_mapping, axis=1)\n",
    "        # It needs to be modified. It is possible to have nan values except for the last 11 days of the time\n",
    "        # Remove last 11 days' missing data. (T_end - T_begin + 1)\n",
    "        factor.fillna(0, inplace=True)\n",
    "        self.factor = factor\n",
    "        self.RAM_USAGE()\n",
    "        print(\"*\" * 60)\n",
    "    def Ensure_position(self, DF):\n",
    "        # We add a column named 'Monday' and change positions every Monday.\n",
    "        DF = DF.shift(1)  # Move one step forward to ensure position\n",
    "        DF[\"Monday\"] = (DF.index.dayofweek == 0).astype(int)  # Shift except Monday\n",
    "\n",
    "        # Get the columns to shift (all columns except 'Monday')\n",
    "        cols_to_shift = DF.columns[DF.columns != \"Monday\"]\n",
    "\n",
    "        DF.loc[DF[\"Monday\"] == 0, cols_to_shift] = np.nan\n",
    "        DF.fillna(method=\"ffill\", \n",
    "                inplace=True)  # Forward fill, holing positions for a week.\n",
    "        DF.fillna(value=0, inplace=True)  # Fill remaining NaN with 0\n",
    "        return DF\n",
    "    def Factor_DF(self):\n",
    "        factor = self.factor\n",
    "        factor_df = factor.pivot(index=\"trade_date\", \n",
    "                                 columns=\"ts_code\", \n",
    "                                 values=f'{self.factor_name}')\n",
    "        self.factor_df = factor_df\n",
    "    def Backtest_Main(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Backtest...\")\n",
    "        factor_df = self.factor_df\n",
    "        # layer number\n",
    "        num_layers = 20\n",
    "\n",
    "        # Calculte the ranks of factors daily.\n",
    "        factor_ranks = factor_df.rank(axis=1, ascending=False)\n",
    "\n",
    "        # The factor ordering is divided into num_layers, each of which allocates funds equally.\n",
    "        layer_allocation = (factor_ranks // (len(factor_df.columns) / num_layers)).fillna(0)\n",
    "        layer_allocation\n",
    "\n",
    "        # import matplotlib.cm as cm\n",
    "\n",
    "        plt.figure()\n",
    "        plt.rcParams[\"axes.unicode_minus\"] = False  # 正常显示负号\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.axhline(y=1, color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "        # Define a color map to use for changing colors progressively\n",
    "        # colors = plt.cm.jet(np.linspace(0, 1, num_layers))\n",
    "\n",
    "        self.profit_long = self.profit_short = None\n",
    "\n",
    "        def Long_Short(Num_layers, Layer, Profit):\n",
    "            long_layer = Num_layers - 1\n",
    "            short_layer = 0\n",
    "            profit_long = self.profit_long\n",
    "            profit_short = self.profit_short\n",
    "            if Layer == short_layer:\n",
    "                profit_short = Profit\n",
    "                # The short profit comes from the decline of the stock.\n",
    "                profit_short = profit_short.apply(\n",
    "                    lambda x: x + 1 if x == 0 else -x + (1 - 0.0003)\n",
    "                )\n",
    "                profit_short = profit_short.cumprod()\n",
    "                profit_short *= 0.5\n",
    "                self.profit_short = profit_short\n",
    "            elif Layer == long_layer:\n",
    "                profit_long = Profit\n",
    "                profit_long = profit_long.apply(\n",
    "                    lambda x: x + 1 if x == 0 else x + (1 - 0.0003)\n",
    "                )\n",
    "                profit_long = profit_long.cumprod()\n",
    "                profit_long *= 0.5\n",
    "                self.profit_long = profit_long\n",
    "\n",
    "        Long_position_df = None\n",
    "        for layer in range(0, num_layers):\n",
    "            # Ensure holding stocks\n",
    "            hold_flag_matrix = layer_allocation.mask(layer_allocation != layer, 0).mask(\n",
    "                layer_allocation == layer, 1)\n",
    "            hold_flag_matrix = self.Ensure_position(hold_flag_matrix)\n",
    "            if layer == 0:\n",
    "                Long_position_df = hold_flag_matrix.copy()\n",
    "\n",
    "            # Delete 'Monday' to fit into yield dataframe.\n",
    "            del hold_flag_matrix[\"Monday\"]\n",
    "\n",
    "            # Calculate the sum of each line in turn.\n",
    "            stock_amount_sum = hold_flag_matrix.sum(axis=1)\n",
    "\n",
    "            # Calculate the weight of each stock. (Average distribution at the same level)\n",
    "            weight_allocation = hold_flag_matrix.apply(\n",
    "                lambda x: x / stock_amount_sum, axis=0).fillna(0)\n",
    "\n",
    "            # Calculate the daily profit rate. And prepare to calculate cumprod.\n",
    "            profit = (weight_allocation * self.price_return).sum(axis=1)\n",
    "\n",
    "            # Create Long and Short position\n",
    "            Long_Short(num_layers, layer, profit)\n",
    "\n",
    "            # Calculate the daily equity and draw.\n",
    "            # Using the 'viridis' colormap with a gradient based on layer number\n",
    "            colors = cm.viridis(layer / num_layers)\n",
    "            profit = profit.apply(lambda x: x + 1 if x == 0 else x + (1 - 0.0003))\n",
    "            profit.cumprod().plot(label=layer, legend=True, color=colors)\n",
    "\n",
    "        profit_HS300 = self.HS_300.apply(lambda x: x + 1 if x == 0 else x + (1 - 0.0003))\n",
    "        profit_HS300.cumprod().plot(label=\"HS 300 index\", legend=True, color=\"r\")\n",
    "        profit_CS500 = self.CS_500.apply(lambda x: x + 1 if x == 0 else x + (1 - 0.0003))\n",
    "        profit_CS500.cumprod().plot(label=\"CS 500 index\", legend=True, color=\"g\")\n",
    "        profit_CS1000 = self.CS_1000.apply(lambda x: x + 1 if x == 0 else x + (1 - 0.0003))\n",
    "        profit_CS1000.cumprod().plot(label=\"CS 1000 index\", legend=True, color=\"b\")\n",
    "\n",
    "        (self.profit_long + self.profit_short).plot(color=\"orange\", label=\"long_short\", legend=True)\n",
    "        plt.title(f\"20-Layered Portfolio Equity ({self.factor_name})\")\n",
    "        plt.legend(title=\"Layer\", bbox_to_anchor=(1, 0.5), loc=\"center left\")\n",
    "        plt.savefig(path + f'{self.factor_name}_Backtest_Main.png', bbox_inches='tight')\n",
    "\n",
    "        self.Long_position_df = Long_position_df\n",
    "        self.RAM_USAGE()\n",
    "        print(\"*\" * 60)\n",
    "    def Backtest_Simple(self, stock_num, Ascending):\n",
    "        # Calculte the ranks of factors daily.\n",
    "        factor_ranks = self.factor_df.rank(axis=1, ascending=Ascending)\n",
    "\n",
    "        # Create position_df based on top 3 ranks\n",
    "        position_df = factor_ranks.apply(lambda x: x <= stock_num).astype(int)\n",
    "        position_df = self.Ensure_position(position_df)\n",
    "\n",
    "        # Delete 'Monday' to fit into yield dataframe.\n",
    "        del position_df[\"Monday\"]\n",
    "\n",
    "        # Calculate the sum of each line in turn.\n",
    "        stock_amount_sum = position_df.sum(axis=1)\n",
    "\n",
    "        # Calculate the weight of each stock. (Average distribution at the same level)\n",
    "        weight_allocation = position_df.apply(\n",
    "            lambda x: x / stock_amount_sum, axis=0\n",
    "        ).fillna(0)\n",
    "\n",
    "        # Calculate the daily profit rate. And prepare to calculate cumprod.\n",
    "        profit = (weight_allocation * self.price_return).sum(axis=1)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.rcParams[\"axes.unicode_minus\"] = False  # 正常显示负号\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.axhline(y=1, color=\"grey\", linestyle=\"--\")\n",
    "        # Calculate the daily equity and draw.\n",
    "        profit = profit.apply(lambda x: x + 1 if x == 0 else x + (1 - 0.0003))\n",
    "        profit.cumprod().plot(label=\"Stocks\", legend=True, color=\"#800080\")\n",
    "\n",
    "        profit_HS300 = self.HS_300.apply(lambda x: x + 1 if x == 0 else x + (1 - 0.0003))\n",
    "        profit_HS300.cumprod().plot(label=\"HS 300 index\", legend=True, color=\"r\")\n",
    "        profit_CS500 = self.CS_500.apply(lambda x: x + 1 if x == 0 else x + (1 - 0.0003))\n",
    "        profit_CS500.cumprod().plot(label=\"CS 500 index\", legend=True, color=\"g\")\n",
    "        profit_CS1000 = self.CS_1000.apply(lambda x: x + 1 if x == 0 else x + (1 - 0.0003))\n",
    "        profit_CS1000.cumprod().plot(label=\"CS 1000 index\", legend=True, color=\"b\")\n",
    "\n",
    "        plt.title(f\"Equity of {stock_num} stocks ({self.factor_name})\")\n",
    "        plt.legend(title=\"Index\", bbox_to_anchor=(1, 0.5), loc=\"center left\")\n",
    "        plt.savefig(path + f'{self.factor_name}_Backtest_Simple.png', bbox_inches='tight')\n",
    "    def Indexes(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Indexes...\")\n",
    "        # 1. RankIC mean(IC mean)\n",
    "        # 2. ICIR\n",
    "        # 3. IC winning rate\n",
    "        # 4. IC t-value\n",
    "        # 5. Long ROI\n",
    "        # 6. Long sharp\n",
    "        # 7. Long retracement\n",
    "        # 8. Long average weekly turnover rate\n",
    "        # ICIR\n",
    "        plt.figure()\n",
    "        IC_series = self.factor_df.corrwith(self.price_return, axis=1, method=\"spearman\")\n",
    "        IC_mean = IC_series.mean()\n",
    "        print(f\"IC mean: {IC_mean}\")\n",
    "        ICIR = IC_series.mean() / IC_series.std()\n",
    "        print(f\"ICIR: {ICIR}\")\n",
    "        IC_series.hist(bins=30)\n",
    "        plt.title(f\"IC frequency histogram ({self.factor_name})\")\n",
    "        plt.savefig(path + f'{self.factor_name}_Indexes_IC.png', bbox_inches='tight')\n",
    "\n",
    "        # RankIC\n",
    "        # Create a figure and axis\n",
    "        plt.figure()\n",
    "        _, ax = plt.subplots(figsize=(8, 4))\n",
    "        # Plot histogram of values on the left side\n",
    "        ax.bar(IC_series.index, IC_series.values)\n",
    "        ax.set_title(f'Histogram of Series Values ({self.factor_name})')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('RankIC')\n",
    "        # Create a twin Axes sharing the xaxis\n",
    "        ax2 = ax.twinx()\n",
    "        # Plot cumulative line on the right side\n",
    "        ax2.plot(IC_series.index, IC_series.cumsum(), color='orange')\n",
    "        ax2.set_ylabel('Cumulative Sum')\n",
    "        plt.savefig(path + f'{self.factor_name}_Indexes_IC_Cum.png', bbox_inches='tight')\n",
    "        \n",
    "        # IC winning rate\n",
    "        IC_winning_rate = sum(1 for ic in IC_series if ic > 0) / len(IC_series)\n",
    "        print(f\"IC winning rate: {IC_winning_rate}\")\n",
    "\n",
    "        t_value = ICIR / sqrt(len(IC_series))\n",
    "        print(f\"IC t-value: {t_value}\")\n",
    "\n",
    "        # Long (Except Short), so `profit_long * 2`\n",
    "        # profit_long is long equity series.\n",
    "        Long_equity = self.profit_long * 2\n",
    "        Long_ROI = (Long_equity[-1]) - 1\n",
    "        print(f\"Long ROI: {Long_ROI}\")\n",
    "\n",
    "        # Max Drawdown\n",
    "        # Calculate the previous peaks\n",
    "        previous_peaks = Long_equity.cummax()\n",
    "        # Calculate the drawdowns\n",
    "        drawdowns = (Long_equity - previous_peaks) / previous_peaks\n",
    "\n",
    "        # Find the maximum drawdown and the dates associated with it\n",
    "        # Convert the index labels to a numeric format\n",
    "        drawdowns.index = pd.to_numeric(drawdowns.index)\n",
    "        max_drawdown = drawdowns.min()\n",
    "        print(f\"Max drawdown: {max_drawdown}\")\n",
    "        max_drawdown_start = drawdowns.idxmin()\n",
    "\n",
    "        # Convert the start and end dates back to the original format if needed\n",
    "        max_drawdown_start = pd.to_datetime(max_drawdown_start).date()\n",
    "        print(f\"Max drawdown begin date: {max_drawdown_start}\")\n",
    "\n",
    "        # Plotting\n",
    "        length = 6\n",
    "        width = 4\n",
    "        plt.figure(figsize=(length, width))\n",
    "        plt.text(0.1, 7/9, f\"IC mean: {IC_mean}\", fontsize=12)\n",
    "        plt.text(0.1, 6/9, f\"ICIR: {ICIR}\", fontsize=12)\n",
    "        plt.text(0.1, 5/9, f\"IC winning rate: {IC_winning_rate}\", fontsize=12)\n",
    "        plt.text(0.1, 4/9, f\"IC t-value: {t_value}\", fontsize=12)\n",
    "        plt.text(0.1, 3/9, f\"Long ROI: {Long_ROI}\", fontsize=12)\n",
    "        plt.text(0.1, 2/9, f\"Max drawdown: {max_drawdown}\", fontsize=12)\n",
    "        plt.text(0.1, 1/9, f\"Max drawdown begin date: {max_drawdown_start}\", fontsize=12)\n",
    "        plt.title(f'Indexes of ({self.factor_name})')\n",
    "        plt.axis('off')  # Turn off axis\n",
    "        plt.savefig(path + f'{self.factor_name}_Indexes.png', bbox_inches='tight')\n",
    "        \n",
    "        print(\"*\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_date = \"20230120\"\n",
    "end_date = \"20240430\"\n",
    "\n",
    "factors_len = len(factors_name)\n",
    "begin_index = 32\n",
    "end_index = factors_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing: ['alpha101_032', 'alpha191_021', 'alpha191_025', 'alpha191_030', 'alpha191_061', 'alpha191_062',\n",
    "# 'alpha191_063', 'alpha191_064', 'alpha191_065', 'alpha191_066', 'alpha191_067', 'alpha191_068', 'alpha191_069',\n",
    "# 'alpha191_070', 'alpha191_072', 'alpha191_073', 'alpha191_074', 'alpha191_075', 'alpha191_076', 'alpha191_077',\n",
    "# 'alpha191_078', 'alpha191_079', 'alpha191_080', 'alpha191_081', 'alpha191_082', 'alpha191_083', 'alpha191_084',\n",
    "# 'alpha191_085', 'alpha191_086', 'alpha191_087', 'alpha191_088', 'alpha191_089', 'alpha191_090', 'alpha191_116',\n",
    "# 'alpha191_143', 'alpha191_147', 'alpha191_182']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor_name in tqdm(factors_name[261: end_index+1], desc=\"Processing factors\", ncols=100):\n",
    "    Single = HS300_Single(factor_name, begin_date, end_date, stocks_code)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, `bbox_inches='tight'` is a parameter used in `plt.savefig()` to ensure that the saved image file includes all elements of the plot without cropping them. It automatically adjusts the bounding box to fit the entire plot area. \n",
    "\n",
    "When you specify `bbox_inches='tight'`, Matplotlib adjusts the bounding box to fit the plot content. This can be helpful to ensure that nothing is cut off when saving the plot, especially when using `plt.tight_layout()` to adjust the layout of the plot.\n",
    "\n",
    "In the provided code snippet:\n",
    "\n",
    "```python\n",
    "plt.savefig('RankIC_combined_plot.png', dpi=300, bbox_inches='tight')\n",
    "```\n",
    "\n",
    "The `bbox_inches='tight'` ensures that all elements of the plot are included in the saved image file, and there is no unnecessary whitespace around the edges. This helps to produce a cleaner and more accurate representation of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HS300_Single_Correlation():\n",
    "    def __init__(self, Factor_Name, Begin_Date, End_Date, Stocks_Code) -> None:\n",
    "        print(f\"Factor: {Factor_Name}\")\n",
    "        self.factor_name = Factor_Name\n",
    "        self.begin_date = Begin_Date\n",
    "        self.end_date = End_Date\n",
    "        self.stocks_code = Stocks_Code\n",
    "        self.Get_Trade_Calendar()\n",
    "        self.Data()\n",
    "        self.Get_Daily_Return()\n",
    "        self.Factor_DF()\n",
    "    def RAM_USAGE(self):\n",
    "        # Get the memory usage of the IPython kernel in MB\n",
    "        ram_usage = process.memory_info().rss / (1024 * 1024)\n",
    "        print(f\"RAM Usage: {ram_usage} MB\")\n",
    "    def Get_Trade_Calendar(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Getting trade calendar...\")\n",
    "        PRICE = get_factor(self.factor_name, \n",
    "                           start_date=self.begin_date, \n",
    "                           end_date=self.end_date, \n",
    "                           ts_code_list=self.stocks_code)\n",
    "        PRICE.reset_index(inplace=True)\n",
    "        PRICE = PRICE.sort_values(by=\"trade_date\").reset_index(drop=True)\n",
    "        # price.set_index(['trade_date', 'ts_code'], inplace=True)\n",
    "        PRICE = PRICE.fillna(0)\n",
    "        PRICE = PRICE.drop_duplicates(subset=['trade_date', 'ts_code'])\n",
    "        PRICE_pivot = PRICE.pivot(index=\"trade_date\", \n",
    "                                  columns=\"ts_code\", \n",
    "                                  values=self.factor_name)\n",
    "\n",
    "        # Attention: len(date_all) >= 60\n",
    "        date_all = PRICE_pivot.index\n",
    "        self.date_all = date_all\n",
    "        # _, date_backtest = train_test_split(date_all, test_size=0.2, shuffle=False)\n",
    "        # backtest_begin = date_backtest[0]\n",
    "        # backtest_end = date_backtest[-1]\n",
    "\n",
    "        # Find missing stocks\n",
    "        all_combinations = pd.MultiIndex.from_product(\n",
    "            [date_all, stocks_code], \n",
    "            names=[\"trade_date\", \"ts_code\"])\n",
    "        all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "        price_whole = pd.merge(\n",
    "            all_combinations_df, \n",
    "            PRICE, \n",
    "            on=[\"trade_date\", \"ts_code\"], \n",
    "            how=\"left\")\n",
    "        missing = price_whole[price_whole.isnull().any(axis=1)]\n",
    "        missing_stock = missing[\"ts_code\"].unique()\n",
    "        print(\"The missing stock:\", missing_stock)\n",
    "\n",
    "        self.stocks_code = list(set(HS300) - set(missing_stock))\n",
    "        print(\"*\" * 60)\n",
    "    def Data(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Get data...\")\n",
    "        # Get factor\n",
    "        factor = get_factor(self.factor_name, \n",
    "                        start_date=self.begin_date, \n",
    "                        end_date=self.end_date, \n",
    "                        ts_code_list=self.stocks_code)\n",
    "        factor.reset_index(inplace=True)\n",
    "        factor = factor.drop_duplicates(subset=['trade_date', 'ts_code'])\n",
    "        self.factor = factor.sort_values(by=\"trade_date\").reset_index(drop=True)\n",
    "\n",
    "        # Get stocks\n",
    "        price = get_price(\n",
    "            ts_code_list=self.stocks_code,\n",
    "            feature_list=[\n",
    "                \"open\",\n",
    "                \"close\"\n",
    "            ],\n",
    "            start_date=self.begin_date,\n",
    "            trade_date=self.end_date,\n",
    "            target_type=\"stock\",\n",
    "        )\n",
    "        price = price.rename(\n",
    "            columns={\n",
    "                \"open\": \"OPEN\",\n",
    "                \"close\": \"CLOSE\"\n",
    "            }\n",
    "        )\n",
    "        price.reset_index(inplace=True)\n",
    "        # Add weekend, If it is Monday, the value is 1, or 0.\n",
    "        # price['Monday'] = (price['trade_date'].dt.dayofweek == 0).astype(int)\n",
    "        self.price = price.sort_values(by=\"trade_date\").reset_index(drop=True)\n",
    "        # price.set_index(['trade_date', 'ts_code'], inplace=True)\n",
    "        # price.fillna(0, inplace=True)\n",
    "        self.RAM_USAGE()\n",
    "        print(\"*\" * 60)\n",
    "    def Get_Daily_Return(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Get daily return...\")\n",
    "        price = self.price\n",
    "        BUY_price = price.pivot(index=\"trade_date\", columns=\"ts_code\", values=\"OPEN\")\n",
    "        SELL_price = price.pivot(index=\"trade_date\", columns=\"ts_code\", values=\"CLOSE\")\n",
    "        price_return = (SELL_price - BUY_price) / BUY_price\n",
    "        self.price_return = price_return.loc[price_return.index.isin(self.date_all), :]\n",
    "        print(\"*\" * 60)\n",
    "    def Data_preprocessing(self):\n",
    "        print(\"*\" * 60)\n",
    "        print(\"Data preprocessing...\")\n",
    "        factor = self.factor\n",
    "        # Data preprocessing\n",
    "        def value_mapping(row):\n",
    "            return value_dict[row[\"trade_date\"]][row[\"ts_code\"]]\n",
    "\n",
    "        # 3MAD\n",
    "        def Col_3MAD(row):\n",
    "            median = row.median()  # median\n",
    "            mad = abs(row - row.median()).median()\n",
    "            threshold = 3 * mad\n",
    "            lower_bound = median - threshold\n",
    "            upper_bound = median + threshold\n",
    "            return row.clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "        indexes = [self.factor_name]\n",
    "        for index in indexes:\n",
    "            df = factor.pivot(index=\"trade_date\", columns=\"ts_code\", values=index)\n",
    "            values = df.values\n",
    "            # Standardize for each row\n",
    "            df = pd.DataFrame(zscore.fit_transform(values.T).T, index=df.index, columns=df.columns)\n",
    "            df = df.apply(Col_3MAD, axis=1)  # 3 times MAD for each row\n",
    "            value_dict = df.to_dict(orient=\"index\")\n",
    "            factor[index + \"_processed\"] = factor.apply(value_mapping, axis=1)\n",
    "        # It needs to be modified. It is possible to have nan values except for the last 11 days of the time\n",
    "        # Remove last 11 days' missing data. (T_end - T_begin + 1)\n",
    "        factor.fillna(0, inplace=True)\n",
    "        self.factor = factor\n",
    "        self.RAM_USAGE()\n",
    "        print(\"*\" * 60)\n",
    "    def Factor_DF(self):\n",
    "        factor = self.factor\n",
    "        factor_df = factor.pivot(index=\"trade_date\", \n",
    "                                 columns=\"ts_code\", \n",
    "                                 values=f'{self.factor_name}')\n",
    "        self.factor_df = factor_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
